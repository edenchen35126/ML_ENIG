import joblib
import pandas as pd
import numpy as np
import os
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# éœéŸ³è­¦å‘Šï¼Œå› å¸¶å…¥çš„dataframe featureè·ŸåŸç”ŸColumnTransformerè£¡é¢çš„features_listä¸ä¸€è‡´
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn")

class CyclicalEncoder(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        self.columns_ = X.columns if isinstance(X, pd.DataFrame) else [f"col_{i}" for i in range(X.shape[1])]
        return self

    def transform(self, X):
        if isinstance(X, np.ndarray):
            X = pd.DataFrame(X, columns=self.columns_)
        return cyclical_encode(X)

    def get_feature_names_out(self, input_features=None):
        if input_features is None:
            input_features = getattr(self, "columns_", [])
        df_temp = pd.DataFrame({c: [0] for c in input_features})
        df_encoded = cyclical_encode(df_temp)
        return df_encoded.columns.to_numpy()

def cyclical_encode(df):
    df = df.copy()
    #out_cols = []
    for c in df.columns:
        if c.endswith("_hour"):
            df[f"{c}_sin"] = np.sin(2 * np.pi * df[c] / 24)
            df[f"{c}_cos"] = np.cos(2 * np.pi * df[c] / 24)
            #out_cols += [f"{c}_sin", f"{c}_cos"]
        elif c.endswith("_dow"):
            df[f"{c}_sin"] = np.sin(2 * np.pi * df[c] / 7)
            df[f"{c}_cos"] = np.cos(2 * np.pi * df[c] / 7)
            #out_cols += [f"{c}_sin", f"{c}_cos"]
        elif c.endswith("_month"):
            df[f"{c}_sin"] = np.sin(2 * np.pi * df[c] / 12)
            df[f"{c}_cos"] = np.cos(2 * np.pi * df[c] / 12)
            #out_cols += [f"{c}_sin", f"{c}_cos"]
    return df


def parse_dates(df: pd.DataFrame, date_cols):
    out = df.copy()
    for c in date_cols:
        try:
            out[c] = pd.to_datetime(out[c], errors="coerce")
        except Exception:
            out[c] = pd.NaT
    return out


def add_date_features(df: pd.DataFrame, date_col: str):
    out = df.copy()
    col = date_col
    out[f"{col}_year"] = out[col].dt.year
    out[f"{col}_month"] = out[col].dt.month
    out[f"{col}_day"] = out[col].dt.day
    out[f"{col}_dow"] = out[col].dt.dayofweek
    out[f"{col}_hour"] = out[col].dt.hour
    return out

# è¼‰å…¥æœ€ä½³æ¨¡å‹
best_model = joblib.load("ml/models/final_rf_without_part_num_divide_v2.pkl")


preprocessor = best_model.named_steps["preprocess"]
feature_names = preprocessor.get_feature_names_out()
print(feature_names)
print("ç‰¹å¾µæ•¸é‡:", len(feature_names))

# print(preprocessor.transformers)

# feature_names = preprocessor.get_feature_names_out()
# print("âœ… æ¨¡å‹å¯¦éš›åƒåˆ°çš„ç‰¹å¾µæ•¸:", len(feature_names))
# print("ğŸ”¹ å‰ 10 å€‹ç‰¹å¾µåç¨±:", feature_names.tolist())


features = ['é‡‘åšä¸‹é™','æ¿å­é¡å‹','æ­¸å±¬ç­åˆ¥','é‡‘åšä¸Šé™','ç·šåˆ¥','æ§½æ¬¡1','é³','æ•¸é‡','æª¢æŸ¥å‹æ…‹','é³åšä¸‹é™','MTO1','é³åšä¸Šé™','é›»æµå€¼1','é›»æµå€¼2','MTO2','é …ç›®']
label_col = "é‡‘"


# æº–å‚™æ–°çš„è³‡æ–™ï¼ˆx_testï¼‰
# dirname ä¸Šä¸€å±¤
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
data_path = os.path.join(BASE_DIR, "data", "raw", "åŒ–é‡‘ç·šè‡ªä¸»æª¢æŸ¥è¡¨_all.csv")
x_test = pd.read_csv(data_path, encoding="big5")


used_time_col = None

used_time_col = "ç”Ÿç”¢æ—¥æœŸ"

if used_time_col:
    x_test = parse_dates(x_test, [used_time_col])
    x_test = add_date_features(x_test, used_time_col)
    #time_features = []
    time_features = [
        f"{used_time_col}_year",
        f"{used_time_col}_month",
        f"{used_time_col}_day",
        f"{used_time_col}_dow", # day of week
        f"{used_time_col}_hour"
    ]
    features.extend(time_features)
else:
    time_features = []


# ç›´æ¥é æ¸¬ â€” ä¸éœ€è¦å†æ‰‹å‹•åš ColumnTransformerï¼
opt_x_test = x_test.iloc[[-1]]

y_pred = best_model.predict(opt_x_test)

print("é æ¸¬çµæœï¼š", y_pred)

y_test = opt_x_test[label_col]
print("çœŸå¯¦æ¨™ç±¤ï¼š", y_test)

# === Evaluate
# mae  = mean_absolute_error(y_test, y_pred)
# mse  = mean_squared_error(y_test, y_pred)
# rmse = np.sqrt(mse)
# r2   = r2_score(y_test, y_pred)
# print(f" MAE={mae:.4f}  MSE={mse:.4f}  RMSE={rmse:.4f}  RÂ²={r2:.4f}")



# === ç‰¹å¾µé‡è¦åº¦
# importances = best_model.named_steps["model"].feature_importances_
# features = best_model.named_steps["preprocess"].get_feature_names_out()

# feat_imp = pd.DataFrame({
#     "feature": features,
#     "importance": importances
# }).sort_values("importance", ascending=False)

# print(feat_imp.head(20))

print(opt_x_test[['MTO1','MTO2','æ­¸å±¬ç­åˆ¥','ç”Ÿç”¢æ—¥æœŸ','æ•¸é‡']])

import optuna
import numpy as np

TARGET = 2.1  # ç›®æ¨™åšåº¦ Î¼m

# mto1_low, mto1_high = 0, 3
# mto2_low, mto2_high = 0, 2.5

current1_low, current1_high = 0, 1.05
current2_low, current2_high = 0, 0.35


# ==== ç›®æ¨™å‡½æ•¸ï¼šåªå„ªåŒ– MTO1 / MTO2ï¼Œå…¶ä»–æ¬„ä½å›ºå®šä½¿ç”¨ row_Test çš„å€¼ ====
def objective(trial: optuna.Trial):
    current11 = trial.suggest_float("é›»æµå€¼1", current1_low, current1_high)
    current12 = trial.suggest_float("é›»æµå€¼2", current2_low, current2_high)

    # å– row_Test çš„ç¬¬ä¸€ç­†ï¼ˆæˆ–ä½ å¯æ”¹æˆ iloc[-1] å–æœ€å¾Œä¸€ç­†ï¼‰
    base_row = opt_x_test.iloc[0].copy()

    # æ›¿æ› MTO1/MTO2ï¼Œå…¶é¤˜æ¬„ä½ç¶­æŒä¸è®Š
    base_row['é›»æµå€¼1'] = current11
    base_row['é›»æµå€¼2'] = current12

    # å»ºç«‹å–®ç­†ç‰¹å¾µ DataFrameï¼ˆæ¬„ä½é †åºèˆ‡è¨“ç·´ä¸€è‡´ï¼‰
    X_new = pd.DataFrame([base_row])

    # ç”±å·²è¨“ç·´æ¨¡å‹æ¨è«–é‡‘åšåº¦
    y_hat = float(best_model.predict(X_new)[0])

    # å–®ç›®æ¨™ï¼šä½¿é æ¸¬åšåº¦è²¼è¿‘ TARGETï¼ˆå¯æ”¹æˆå¹³æ–¹èª¤å·®æˆ– Huberï¼‰
    loss = abs(y_hat - TARGET)
    #loss = (y_hat - TARGET) ** 2


    # ï¼ˆé¸é…ï¼‰ä½ ä¹Ÿå¯åŠ å…¥è£½ç¨‹é¢¨éšª/æˆæœ¬æ‡²ç½°ï¼Œä¾‹å¦‚åé›¢åç¾©å€¼ï¼š
    # loss += 0.001 * max(0, mto1 - åç¾©ä¸Šé™) + 0.001 * max(0, åç¾©ä¸‹é™ - mto1)
    
    return loss

# ==== åŸ·è¡Œæœ€ä½³åŒ– ====
study = optuna.create_study(direction="minimize", sampler=optuna.samplers.TPESampler(seed=42))
study.optimize(objective, n_trials=100, show_progress_bar=False)

# ==== æœ€ä½³è§£è¼¸å‡º ====
best_params = study.best_trial.params
best_row = opt_x_test.iloc[0].copy()
best_row['é›»æµå€¼1'] = best_params['é›»æµå€¼1']
best_row['é›»æµå€¼2'] = best_params['é›»æµå€¼2']

X_best = pd.DataFrame([best_row])
pred_best = float(best_model.predict(X_best)[0])

print("\n=== Optimization Result ===")
print("Best params:", best_params)                 # {'MTO1': ..., 'MTO2': ...}
print("Predicted thickness:", pred_best)           # æœ€ä½³åƒæ•¸ä¸‹çš„é æ¸¬é‡‘åšåº¦
print("Abs error to TARGET:", abs(pred_best - TARGET))